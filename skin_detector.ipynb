{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "335271d7-9b56-4bf6-8c04-7dcbb1db421b",
   "metadata": {},
   "source": [
    "<h1>Skin detector</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d68ff14-8f44-4141-bfd9-3a912dda3391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "import os\n",
    "\n",
    "TRAIN_PATH = '../datasets/skin_cancer/train'\n",
    "TEST_PATH = '../datasets/skin_cancer/test'\n",
    "#tensorflow = channel last\n",
    "#theano = channel first\n",
    "print(K.backend())\n",
    "K.set_image_data_format(data_format='channels_last')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceef440a-39d6-4bf5-8a2c-77dba3ebd8cc",
   "metadata": {},
   "source": [
    "\"The data consists of two folders with each <strong>1800</strong> pictures <strong>(224x224)</strong> of the two types of moles.\"</br>\n",
    "<strong>The goal is to predict if a skin spot is either benign or malignant.</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e8fd78-31d6-4f9d-86d1-71ac52b734af",
   "metadata": {},
   "source": [
    "<h2>Building datasets</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f203e175-d479-40b7-855f-2f32a14863aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_array(train_test_path, benign_malign_path, width, height):\n",
    "    complete_path = f'{train_test_path}/{benign_malign_path}/'\n",
    "    X = np.empty(shape=(len(os.listdir(complete_path)), width, height)) #1440 images of 224x224 pixels in RGB but for computation reason we will use grayscale\n",
    "    for i, image_file in enumerate(os.listdir(complete_path)):\n",
    "        im = ImageOps.grayscale(Image.open(f'{complete_path}{image_file}')) #from (224, 224, 3) to (224, 224)\n",
    "        X[i] = np.array(im)\n",
    "    if benign_malign_path == 'benign':\n",
    "        y = np.zeros(shape=X.shape[0])\n",
    "    elif benign_malign_path == 'malignant':\n",
    "        y = np.ones(shape=X.shape[0])\n",
    "    else:\n",
    "        print('benign_malign_path must be \"benign\" or \"malign\"')\n",
    "    return X, y\n",
    "\n",
    "def shuffle_in_unison(a, b):\n",
    "    \"\"\"\n",
    "        Shuffle two array in the same order (see: https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison)\n",
    "    \"\"\"\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fae2e26-7457-4e12-b999-de5356b49c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_benign, y_train_benign = create_array(train_test_path=TRAIN_PATH, benign_malign_path='benign', width=224, height=224)\n",
    "X_train_malign, y_train_malign = create_array(train_test_path=TRAIN_PATH, benign_malign_path='malignant', width=224, height=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc81721f-563b-4b68-93e6-bc7da7622061",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_benign, y_test_benign = create_array(train_test_path=TEST_PATH, benign_malign_path='benign', width=224, height=224)\n",
    "X_test_malign, y_test_malign = create_array(train_test_path=TEST_PATH, benign_malign_path='malignant', width=224, height=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2656ad6b-1d8f-4e21-b8ee-f37987308ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 224, 224) (1440,)\n",
      "(1197, 224, 224) (1197,)\n",
      "(2637, 224, 224) (2637,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_benign.shape, y_train_benign.shape)\n",
    "print(X_train_malign.shape, y_train_malign.shape)\n",
    "\n",
    "X_train = np.concatenate((X_train_benign, X_train_malign), axis=0)\n",
    "y_train = np.concatenate((y_train_benign, y_train_malign), axis=0)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b3b84b4-1d8d-41a2-93c4-d97332a7d733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 224, 224) (360,)\n",
      "(300, 224, 224) (300,)\n",
      "(660, 224, 224) (660,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_benign.shape, y_test_benign.shape)\n",
    "print(X_test_malign.shape, y_test_malign.shape)\n",
    "\n",
    "X_test = np.concatenate((X_test_benign, X_test_malign), axis=0)\n",
    "y_test = np.concatenate((y_test_benign, y_test_malign), axis=0)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd9ec5f5-14c7-4f31-a2a9-9d1c2b28644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_in_unison(X_train, y_train)\n",
    "shuffle_in_unison(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8b66bf-3996-454c-989e-b4575b7ac3c5",
   "metadata": {},
   "source": [
    "<h2>Processing data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8a10d93-bf5d-4a0f-adbf-da07d7d201c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(X, y):\n",
    "    X = X[:, :, :, np.newaxis]\n",
    "    y = np.reshape(y, newshape=(y.shape[0], 1))\n",
    "    return X, y\n",
    "\n",
    "def rescale(X, y):\n",
    "    X = X.astype('float32')\n",
    "    return X/255, np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc2ad78-120a-479b-a6b0-1bc9e601eab2",
   "metadata": {},
   "source": [
    "<h3>Resizing :</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3b13765-efbe-47da-a84f-e169be914804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2637, 224, 224, 1) (660, 224, 224, 1)\n",
      "(2637, 1) (660, 1)\n"
     ]
    }
   ],
   "source": [
    "#we need a n * (width, height, 1) shape (channels_last)\n",
    "X_train, y_train = resize(X_train, y_train)\n",
    "X_test, y_test = resize(X_test, y_test)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f785dbe6-0378-4769-8189-7992ba1192fc",
   "metadata": {},
   "source": [
    "<h3>Rescaling :</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa268cc-a0e2-4777-a682-c89852629202",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = rescale(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23629793-0a44-4a8f-91fe-1d68c2c954ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = rescale(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d04794-ca3c-4983-998c-d15fa5a52b0e",
   "metadata": {},
   "source": [
    "<h2>Modelling :</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8854e322-0f69-48f7-8841-59fd4947023f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e40dbd-3b96-4da5-87c5-02c1e1b4a97d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
